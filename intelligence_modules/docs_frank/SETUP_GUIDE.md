# Causal Intelligence Module (CIM) Setup Guide

This guide provides step-by-step instructions for setting up the CIM in both local development environments and n8n Cloud/Self-Hosted workflows.

---

## üöÄ Part 1: Local Setup Workflow

Use this for development, deep analysis, and when you have full control over your Python environment.

### 1. Prerequisites
*   **Python 3.10+**
*   **Git** (optional, for version control)

### 2. Installation
1.  **Clone or Download** the project to your local machine.
2.  **Install Dependencies**:
    The local module uses powerful libraries for full causal inference.
    ```bash
    pip install networkx numpy scipy pandas
    ```

### 3. Verification
Run the integrated test suite to ensure your environment is configured correctly:
```bash
python -m tests.test_module
```

### 4. Running Your First Query
Test the "Gatekeeper" CLI:
```bash
python cim.py "/c Why are our conversion rates dropping?" --visual --prompt
```
*Check the `logs/causal_traces/` folder for your first reasoning trace!*

---

## ‚òÅÔ∏è Part 2: n8n Cloud Deployment Guide

Use this for managed n8n Cloud environments where you cannot access the file system or install custom libraries.

### 1. The Architecture
In n8n, you will use a **"Unified Builder"** node. This node contains all the logic and data (Priors, Domain Graphs, Procedures) embedded in a single script.

### 2. Workflow Setup Steps
1.  **Create a New Workflow** in n8n.
2.  **Add a Trigger** (e.g., HTTP Request, Slack, or Manually).
3.  **Add a "Python Code" Node**:
    *   **Node Name**: `Causal Graph Builder`
    *   **Language**: `Python`
    *   **Code**: Copy the entire content of `cloud_n8n_code_tools/unified_graph_builder_n8n.py` and paste it here.
4.  **Add a "Switch" Node** (Optional):
    *   Route based on the output `cim_active` boolean to decide whether to send the graph to an LLM or skip it for standard queries.
5.  **Add an "AI Agent" or "OpenAI" Node**:
    *   Pass the `causal_prompt` generated by your Python node to the system prompt of the LLM.

### 3. Handling Math Tools in n8n
If you need deterministic calculations (e.g., Effect Size):
1.  Add another **Python Code** node.
2.  Paste the content of `cloud_n8n_code_tools/causal_math_tools_n8n_v.py`.
3.  Send your data as an input item with an `operation` field (e.g., `{"operation": "effect_size"}`).

---

## üõ†Ô∏è Part 3: n8n Self-Hosted (Docker) Setup

If you run n8n in Docker, you can use the **Full Causal Library** instead of the "Lite" versions.

### 1. Configure Docker
Add the required Python libraries to your `docker-compose.yaml` or Dockerfile:
```yaml
environment:
  - NODE_FUNCTION_ALLOW_EXTERNAL=networkx,numpy,scipy,pandas
```

### 2. Link the Library
Ensure the `INTELLIGENCE MODULES` directory is mounted as a volume so the Python node can find the files:
```yaml
volumes:
  - /path/to/INTELLIGENCE MODULES:/data/intelligence
```

---

## üìñ Related Documentation
*   [Command Guide](docs/COMMAND_GUIDE.md): For detail on CLI flags and slash commands.
*   [Architecture Overview](docs/ARCHITECTURE_OVERVIEW.md): To understand the 3-stage Snowball retrieval.
