tool_id,tool_name,class_name,method_name,description,parameters_schema,return_type,usage_example
cmt_001,Calculate Effect Size,CausalMathTools,calculate_effect_size,"Calculate Cohen's d effect size between treatment and control groups deterministically. Useful for measuring the magnitude of a causal effect.","{'treatment_mean': 'float', 'control_mean': 'float', 'pooled_std': 'float'}","float","CausalMathTools.calculate_effect_size(treatment_mean=10.5, control_mean=8.2, pooled_std=2.1)"
cmt_002,Calculate Confidence Interval,CausalMathTools,calculate_confidence_interval,"Calculate proper confidence interval for a mean given standard error and confidence level. Essential for reporting uncertainty.","{'mean': 'float', 'std_error': 'float', 'confidence_level': 'float=0.95'}","Tuple[float, float]","CausalMathTools.calculate_confidence_interval(mean=10.0, std_error=1.5)"
cmt_003,Bayesian Update,CausalMathTools,bayes_update,"Perform Bayesian update of probability given prior and likelihoods. Fundamental for updating causal beliefs with new evidence.","{'prior': 'float', 'likelihood_h1': 'float', 'likelihood_h0': 'float'}","float","CausalMathTools.bayes_update(prior=0.3, likelihood_h1=0.8, likelihood_h0=0.2)"
cmt_004,Calculate Correlation,CausalMathTools,calculate_correlation,"Calculate Pearson correlation coefficient and p-value. Determines strength of linear relationship between variables.","{'x': 'List[float]', 'y': 'List[float]'}","Tuple[float, float]","CausalMathTools.calculate_correlation(x=[1,2,3], y=[2,4,6])"
cmt_005,Partial Correlation,CausalMathTools,partial_correlation,"Calculate partial correlation between x and y controlling for z. key for identifying direct causal links by removing confounder influence.","{'x': 'np.ndarray', 'y': 'np.ndarray', 'z': 'np.ndarray'}","float","CausalMathTools.partial_correlation(x=x_array, y=y_array, z=z_control)"
cmt_006,Power Analysis,CausalMathTools,power_analysis,"Calculate statistical power for hypothesis testing given effect size and sample size. Ensures experiments are properly powered.","{'effect_size': 'float', 'alpha': 'float=0.05', 'n': 'int=100'}","float","CausalMathTools.power_analysis(effect_size=0.5, n=150)"
gtt_001,Find Top K Paths,GraphTraversalTools,find_top_k_paths,"Find the top k weighted paths between source and target nodes in a causal graph. Identifies most likely causal chains.","{'graph': 'nx.DiGraph', 'source': 'str', 'target': 'str', 'k': 'int=5', 'weight_attr': 'str=weight'}","List[Tuple[List[str], float]]","GraphTraversalTools.find_top_k_paths(graph=G, source='A', target='B', k=3)"
gtt_002,Find Strongest Path,GraphTraversalTools,find_strongest_path,"Identify the single strongest path between two nodes. Used for primary causal mechanism identification.","{'graph': 'nx.DiGraph', 'source': 'str', 'target': 'str', 'weight_attr': 'str=weight'}","Optional[Tuple[List[str], float]]","GraphTraversalTools.find_strongest_path(graph=G, source='A', target='B')"
gtt_003,Detect Contradictions,GraphTraversalTools,detect_contradictions,"Detect contradictory edges (e.g., positive vs negative) between the same nodes in a graph. Flags logical inconsistencies in the causal model.","{'graph': 'nx.DiGraph', 'edge_type_attr': 'str=edge_type'}","List[Dict]","GraphTraversalTools.detect_contradictions(graph=G)"
gtt_004,Calculate Node Centrality,GraphTraversalTools,calculate_node_centrality,"Calculate betweenness centrality to identify critical nodes or bottlenecks. Highlights hubs of causal influence.","{'graph': 'nx.DiGraph'}","Dict[str, float]","GraphTraversalTools.calculate_node_centrality(graph=G)"
gtt_005,Identify Bottlenecks,GraphTraversalTools,identify_bottlenecks,"Identify bottleneck nodes that appear in all paths from source to target. Critical mediators that control the flow of causality.","{'graph': 'nx.DiGraph', 'source': 'str', 'target': 'str'}","List[str]","GraphTraversalTools.identify_bottlenecks(graph=G, source='start', target='end')"
hr_001,Score Hypothesis,HypothesisRanking,score_hypothesis,"Score a single hypothesis based on evidence quality, weight, and penalties. deterministic scoring engine.","{'hypothesis': 'Dict', 'evidence_list': 'List[EvidenceScore]', 'penalties': 'Optional[Dict]'}","float","HypothesisRanking.score_hypothesis(hypothesis=h1, evidence_list=ev_list)"
hr_002,Rank Hypotheses,HypothesisRanking,rank_hypotheses,"Rank multiple hypotheses deterministically based on evidence scores. Sorting logic for competing causal explanations.","{'hypotheses': 'List[Dict]', 'evidence_map': 'Dict', 'penalties': 'Optional[Dict]'}","List[Tuple[Dict, float]]","HypothesisRanking.rank_hypotheses(hypotheses=h_list, evidence_map=e_map)"
hr_003,Bradford Hill Criteria,HypothesisRanking,apply_bradford_hill_criteria,"Evaluate causal strength using Bradford Hill criteria like temporality, specificity, and coherence. The gold standard for causal inference validation.","{'strength': 'float', 'consistency': 'float', 'specificity': 'float', 'temporality': 'float', 'gradient': 'float', 'plausibility': 'float', 'coherence': 'float', 'experiment': 'float', 'analogy': 'float'}","float","HypothesisRanking.apply_bradford_hill_criteria(strength=0.8, temporality=1.0, consistency=0.9, ...)"
vt_001,Validate Plan Completeness,ValidationTools,validate_plan_completeness,"Check if a reasoning plan contains all required fields. Ensures structural integrity of cognitive artifacts.","{'plan': 'Dict', 'required_fields': 'List[str]'}","Tuple[bool, List[str]]","ValidationTools.validate_plan_completeness(plan=my_plan, required_fields=['goal', 'steps'])"
vt_002,Enforce Token Budget,ValidationTools,enforce_token_budget,"Truncate text to fit within a specific token budget. Prevents context overflow in LLM calls.","{'text': 'str', 'max_tokens': 'int', 'tokenizer_avg_chars_per_token': 'float=4.0'}","str","ValidationTools.enforce_token_budget(text=long_text, max_tokens=1000)"
vt_003,Check DAG Validity,ValidationTools,check_dag_validity,"Verify if a graph is a valid Directed Acyclic Graph (DAG) by checking for cycles. logic gate for causal diagrams.","{'graph': 'nx.DiGraph'}","Tuple[bool, Optional[List]]","ValidationTools.check_dag_validity(graph=G)"
vt_004,Verify Temporal Consistency,ValidationTools,verify_temporal_consistency,"Check that causes chronologically precede their effects in a list of events. Enforces causality's primary law.","{'events': 'List[Dict]', 'time_key': 'str=timestamp'}","Tuple[bool, List[str]]","ValidationTools.verify_temporal_consistency(events=event_log)"
ms_001,Score Memory Relevance,MemoryScoring,score_memory_relevance,"Score memory relevance using embeddings, recency, and importance. Deterministic retrieval grading.","{'memory_embedding': 'np.ndarray', 'query_embedding': 'np.ndarray', 'recency_weight': 'float', 'importance_weight': 'float'}","float","MemoryScoring.score_memory_relevance(memory_embedding=emb1, query_embedding=q_emb)"
ms_002,Rank Memories,MemoryScoring,rank_memories,"Rank memories by relevance and return top-k. Deterministic sorting for context retrieval.","{'memories': 'List[Dict]', 'query_embedding': 'np.ndarray', 'top_k': 'int=10'}","List[Tuple[Dict, float]]","MemoryScoring.rank_memories(memories=all_mems, query_embedding=q_emb)"
cmt_007,Sensitivity Analysis,CausalMathTools,calculate_tipping_point,"Calculates the robustness of a causal claim against unmeasured confounders. Provides a 'Tipping Point' score.","{'observed_effect': 'float', 'standard_error': 'float', 'alpha': 'float=0.05'}","Dict[str, float]","CausalMathTools.calculate_tipping_point(observed_effect=2.5, standard_error=0.4)"
